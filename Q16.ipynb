{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 16: \n",
    "The dataset in hands is rich as there is a lot of metadata to each tweet. Be creative and propose a new problem (something interesting that can be inferred from this dataset) other than the previous parts. You can look into the literature of Twitter data analysis to get some ideas. Implement your idea and show that it works. As a suggestion, you might provide some analysis based on changes of tweet sentiments for fans of the opponent teams participating in the match. You get full credit for briniging in novelty and full or partial implementation of your new ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use-case : Predicting number of impressions for a given tweet\n",
    "* the impressions for a tweet are present in the tweet['metrics'] object inside the json\n",
    "* some possible features for this could be; user-passivity, created-hour, no.of hashtags, sentiment of tweet, no. of followers of author, no. of tweets made by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tags = ['#gohawks','#gopatriots','#nfl','#patriots','#sb49','#superbowl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(data, fileName):\n",
    "    with open('pynb_data/'+fileName + \".pickle\", 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(fileName):\n",
    "    try:\n",
    "        with open('pynb_data/'+fileName + \".pickle\", 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return data\n",
    "    except IOError:\n",
    "        print(\"Could not read file: \" + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def getMinAndMaxTs(tag):\n",
    "    filename = 'data/tweets_'+tag+'.txt'\n",
    "    max_ts = 0\n",
    "    min_ts = 1552522378\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            timestamp = json_object['citation_date']\n",
    "            if(timestamp < min_ts):                \n",
    "                min_ts = timestamp\n",
    "            \n",
    "            if(timestamp > max_ts):\n",
    "                max_ts = timestamp\n",
    "                \n",
    "    return [min_ts,max_ts]\n",
    "\n",
    "tagsToMinTs = {}\n",
    "tagsToMaxTs = {}\n",
    "for tag in hash_tags:\n",
    "    ts_list = getMinAndMaxTs(tag)\n",
    "    tagsToMinTs[tag] = (ts_list[0])\n",
    "    tagsToMaxTs[tag] = (ts_list[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# https://arxiv.org/pdf/1401.2018v2.pdf\n",
    "def getUserPassivity(user,ts):\n",
    "    createdDateTimeObj = datetime.datetime.strptime(user['created_at'],\"%a %b %d %H:%M:%S %z %Y\")\n",
    "    created = datetime.datetime.fromtimestamp(createdDateTimeObj.timestamp())\n",
    "    d = datetime.datetime.fromtimestamp(ts)\n",
    "    td = (created - d).days\n",
    "    statuses_count = user['statuses_count']\n",
    "    return td/(1.0+statuses_count)\n",
    "\n",
    "def getLocalHour(timestamp):\n",
    "    d = datetime.datetime.fromtimestamp(timestamp)\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    d = pst.localize(d)\n",
    "    return d.hour\n",
    "\n",
    "def getWindowNumber(start_ts, curr_ts, window):\n",
    "    elapsed = (curr_ts - start_ts)/(window*1.0)\n",
    "    windowNum = math.ceil(elapsed)\n",
    "    return windowNum    \n",
    "\n",
    "def getFeatures(start_ts,end_ts,window):\n",
    "    windowToTweets = {}\n",
    "    windowToRetweets = {}\n",
    "    windowToFollowerCount = {}\n",
    "    windowToMaxFollowers = {}\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for tag in hash_tags:\n",
    "        filename = 'data/tweets_'+tag+'.txt'\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                json_object = json.loads(line)\n",
    "                timestamp = json_object['citation_date']\n",
    "\n",
    "                if timestamp < start_ts or timestamp > end_ts:                            \n",
    "                    continue\n",
    "\n",
    "                impressions = json_object['metrics']['impressions']\n",
    "                userPassivity = getUserPassivity(json_object['tweet']['user'],timestamp)\n",
    "                h = getLocalHour(timestamp)\n",
    "                hashtagCount = len(json_object['tweet']['entities']['hashtags'])\n",
    "                followerCount = json_object['author']['followers']\n",
    "                tweetCount = json_object['tweet']['user']['statuses_count']\n",
    "\n",
    "                features.append([userPassivity,h,hashtagCount,followerCount,tweetCount])\n",
    "                labels.append(impressions)                                \n",
    "                \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Model for #superbowl\n",
      "\n",
      "MSE : 3615741434.205783\n",
      "R-squared : 0.8770361550012772\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.877\n",
      "Model:                            OLS   Adj. R-squared:                  0.877\n",
      "Method:                 Least Squares   F-statistic:                 8.612e+05\n",
      "Date:                Wed, 20 Mar 2019   Prob (F-statistic):               0.00\n",
      "Time:                        16:20:05   Log-Likelihood:            -7.5004e+06\n",
      "No. Observations:              603742   AIC:                         1.500e+07\n",
      "Df Residuals:                  603736   BIC:                         1.500e+07\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1701.9881    234.843      7.247      0.000    1241.703    2162.273\n",
      "x1             4.5859      5.097      0.900      0.368      -5.403      14.575\n",
      "x2           -37.1467     14.192     -2.617      0.009     -64.963      -9.331\n",
      "x3          -197.9048     43.447     -4.555      0.000    -283.059    -112.751\n",
      "x4             0.9938      0.000   2070.474      0.000       0.993       0.995\n",
      "x5             0.0011      0.001      0.773      0.440      -0.002       0.004\n",
      "==============================================================================\n",
      "Omnibus:                  2640666.195   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   12347310645446.473\n",
      "Skew:                         136.983   Prob(JB):                         0.00\n",
      "Kurtosis:                   22156.018   Cond. No.                     4.94e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.94e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tools.eval_measures as ste\n",
    "\n",
    "min_ts = min(list(tagsToMinTs.values()))\n",
    "\n",
    "#tp1\n",
    "tp1_window_size = 3600 # 1 hour window size\n",
    "tp1_start_ts = tp1_window_size * math.floor(min_ts/(tp1_window_size*1.0))\n",
    "tp1_end_ts = 1422806400\n",
    "features,labels = getFeatures(tp1_start_ts,tp1_end_ts,tp1_window_size)\n",
    "save_object(features, \"q16_tp1_features\")\n",
    "save_object(labels, \"q16_tp1_labels\")\n",
    "\n",
    "print('\\nLinear Regression Model for {}'.format(tag))\n",
    "X = features\n",
    "y = labels\n",
    "    \n",
    "#     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(X)\n",
    "print(\"\\nMSE : {}\".format(ste.mse(pred_y, y,axis=0)))\n",
    "print(\"R-squared : {}\".format(results.rsquared))    \n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Model for #superbowl\n",
      "\n",
      "MSE : 67146716.77004832\n",
      "R-squared : 0.9967625943023873\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.997\n",
      "Model:                            OLS   Adj. R-squared:                  0.997\n",
      "Method:                 Least Squares   F-statistic:                 1.213e+08\n",
      "Date:                Wed, 20 Mar 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:00:33   Log-Likelihood:            -2.0553e+07\n",
      "No. Observations:             1970528   AIC:                         4.111e+07\n",
      "Df Residuals:                 1970522   BIC:                         4.111e+07\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -120.7022     37.469     -3.221      0.001    -194.140     -47.265\n",
      "x1             0.1324      0.341      0.389      0.697      -0.535       0.800\n",
      "x2             8.2253      2.307      3.565      0.000       3.704      12.747\n",
      "x3             6.3038      4.821      1.308      0.191      -3.144      15.752\n",
      "x4             0.9798      4e-05   2.45e+04      0.000       0.980       0.980\n",
      "x5             0.0012      0.000      5.566      0.000       0.001       0.002\n",
      "=================================================================================\n",
      "Omnibus:                 12826415.645   Durbin-Watson:                      1.999\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   14005997734299344.000\n",
      "Skew:                         582.613   Prob(JB):                            0.00\n",
      "Kurtosis:                  413021.603   Cond. No.                        9.45e+05\n",
      "=================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.45e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tools.eval_measures as ste\n",
    "\n",
    "min_ts = min(list(tagsToMinTs.values()))\n",
    "\n",
    "#tp2\n",
    "tp2_window_size = 300 # 5 minute window size\n",
    "tp2_start_ts = 1422806400\n",
    "tp2_end_ts = 1422849600\n",
    "features,labels = getFeatures(tp2_start_ts,tp2_end_ts,tp2_window_size)\n",
    "save_object(features, \"q16_tp2_features\")\n",
    "save_object(labels, \"q16_tp2_labels\")\n",
    "\n",
    "print('\\nLinear Regression Model for {}'.format(tag))\n",
    "X = features\n",
    "y = labels\n",
    "    \n",
    "#     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(X)\n",
    "print(\"\\nMSE : {}\".format(ste.mse(pred_y, y,axis=0)))\n",
    "print(\"R-squared : {}\".format(results.rsquared))    \n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Model for #superbowl\n",
      "\n",
      "MSE : 4638475443.966269\n",
      "R-squared : 0.8994272160994153\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.899\n",
      "Model:                            OLS   Adj. R-squared:                  0.899\n",
      "Method:                 Least Squares   F-statistic:                 4.454e+05\n",
      "Date:                Wed, 20 Mar 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:05:06   Log-Likelihood:            -3.1250e+06\n",
      "No. Observations:              249046   AIC:                         6.250e+06\n",
      "Df Residuals:                  249040   BIC:                         6.250e+06\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1251.5539    367.219      3.408      0.001     531.814    1971.294\n",
      "x1             2.9717      6.499      0.457      0.647      -9.766      15.709\n",
      "x2            31.6376     21.298      1.485      0.137     -10.106      73.381\n",
      "x3          -277.3766     72.851     -3.807      0.000    -420.163    -134.590\n",
      "x4             0.9944      0.001   1487.415      0.000       0.993       0.996\n",
      "x5            -0.0013      0.002     -0.562      0.574      -0.006       0.003\n",
      "==============================================================================\n",
      "Omnibus:                  1173822.843   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   14928811119170.568\n",
      "Skew:                         175.979   Prob(JB):                         0.00\n",
      "Kurtosis:                   37930.983   Cond. No.                     5.56e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.56e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tools.eval_measures as ste\n",
    "\n",
    "max_ts = min(list(tagsToMaxTs.values()))\n",
    "\n",
    "#tp3\n",
    "tp3_window_size = 3600 # 1 hour window size\n",
    "tp3_start_ts = 1422849600\n",
    "tp3_end_ts = tp3_window_size * math.ceil(max_ts/(tp3_window_size*1.0))\n",
    "features,labels = getFeatures(tp3_start_ts,tp3_end_ts,tp3_window_size)\n",
    "save_object(features, \"q16_tp3_features\")\n",
    "save_object(labels, \"q16_tp3_labels\")\n",
    "\n",
    "print('\\nLinear Regression Model for {}'.format(tag))\n",
    "X = features\n",
    "y = labels\n",
    "    \n",
    "#     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "pred_y = results.predict(X)\n",
    "print(\"\\nMSE : {}\".format(ste.mse(pred_y, y,axis=0)))\n",
    "print(\"R-squared : {}\".format(results.rsquared))    \n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
