{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 7: \n",
    "    \n",
    "Also, aggregate the data of all hashtags, and train 3 models (for the intervals mentioned above) to predict the number of tweets in the next hour on the aggregated data.\n",
    "Perform the same evaluations on your combined model and compare with models you trained for individual hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tags = ['#gohawks','#gopatriots','#nfl','#patriots','#sb49','#superbowl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(data, fileName):\n",
    "    with open('pynb_data/'+fileName + \".pickle\", 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(fileName):\n",
    "    try:\n",
    "        with open('pynb_data/'+fileName + \".pickle\", 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return data\n",
    "    except IOError:\n",
    "        print(\"Could not read file: \" + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def getMinAndMaxTs(tag):\n",
    "    filename = 'data/tweets_'+tag+'.txt'\n",
    "    max_ts = 0\n",
    "    min_ts = 1552522378\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            timestamp = json_object['citation_date']\n",
    "            if(timestamp < min_ts):                \n",
    "                min_ts = timestamp\n",
    "            \n",
    "            if(timestamp > max_ts):\n",
    "                max_ts = timestamp\n",
    "                \n",
    "    return [min_ts,max_ts]\n",
    "\n",
    "tagsToMinTs = {}\n",
    "tagsToMaxTs = {}\n",
    "for tag in hash_tags:\n",
    "    ts_list = getMinAndMaxTs(tag)\n",
    "    tagsToMinTs[tag] = (ts_list[0])\n",
    "    tagsToMaxTs[tag] = (ts_list[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def getLocalHour(timestamp):\n",
    "    d = datetime.datetime.fromtimestamp(timestamp)\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    d = pst.localize(d)\n",
    "    return d.hour\n",
    "\n",
    "def getWindowNumber(start_ts, curr_ts, window):\n",
    "    elapsed = (curr_ts - start_ts)/(window*1.0)\n",
    "    windowNum = math.ceil(elapsed)\n",
    "    return windowNum    \n",
    "\n",
    "def getFeatures(start_ts,end_ts,window):\n",
    "    windowToTweets = {}\n",
    "    windowToRetweets = {}\n",
    "    windowToFollowerCount = {}\n",
    "    windowToMaxFollowers = {}\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for tag in hash_tags:\n",
    "        filename = 'data/tweets_'+tag+'.txt'\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                json_object = json.loads(line)\n",
    "                timestamp = json_object['citation_date']\n",
    "            \n",
    "                if timestamp < start_ts or timestamp > end_ts:                            \n",
    "                    continue\n",
    "                \n",
    "                key = getWindowNumber(start_ts,timestamp,window)\n",
    "    #             print(key)\n",
    "                if key not in windowToTweets.keys():\n",
    "                    windowToTweets[key]=0\n",
    "                windowToTweets[key]+=1\n",
    "            \n",
    "                retweetCount = json_object['metrics']['citations']['total']        \n",
    "            \n",
    "                if key not in windowToRetweets.keys():\n",
    "                    windowToRetweets[key]=0\n",
    "                windowToRetweets[key]+=retweetCount\n",
    "        \n",
    "                followerCount = json_object['author']['followers']\n",
    "                if key not in windowToFollowerCount.keys():\n",
    "                    windowToFollowerCount[key]=0\n",
    "                windowToFollowerCount[key]+=followerCount\n",
    "        \n",
    "                if key not in windowToMaxFollowers.keys():\n",
    "                    windowToMaxFollowers[key]=0\n",
    "                windowToMaxFollowers[key] = max(windowToMaxFollowers[key],followerCount)            \n",
    "            \n",
    "    for period in range(start_ts,end_ts,window):\n",
    "        key = getWindowNumber(start_ts,period,window)\n",
    "        tweetCount = windowToTweets.get(key, 0)\n",
    "        retweetCount = windowToRetweets.get(key,0)\n",
    "        followerCount = windowToFollowerCount.get(key,0)\n",
    "        maxFollowers = windowToMaxFollowers.get(key,0)\n",
    "\n",
    "        h = getLocalHour(key)\n",
    "            \n",
    "        feature = [tweetCount, retweetCount, followerCount, maxFollowers, h]\n",
    "        features.append(feature)\n",
    "                \n",
    "        nextKey = getWindowNumber(start_ts, period + window, window)\n",
    "        labels.append(windowToTweets.get(nextKey,0))\n",
    "                \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "[111, 89, 110, 100, 137, 169, 215, 353, 569, 533, 530, 544, 525, 628, 611, 675, 260, 256, 233, 342, 402, 334, 258, 119, 88, 275, 155, 173, 336, 160, 291, 479, 632, 563, 304, 528, 651, 534, 626, 614, 376, 398, 496, 387, 243, 258, 203, 65, 145, 34, 20, 42, 180, 115, 185, 687, 885, 954, 704, 981, 1032, 825, 884, 799, 474, 799, 724, 473, 459, 337, 334, 236, 125, 103, 82, 133, 218, 93, 192, 309, 500, 612, 430, 710, 783, 687, 686, 670, 428, 712, 697, 614, 619, 542, 582, 417, 434, 347, 139, 21, 312, 544, 1141, 1839, 2459, 3087, 2493, 6380, 10260, 6702, 7271, 39421, 14572, 8757, 22584, 18564, 4389, 2640, 1997, 1413, 914, 709, 721, 666, 1510, 1123, 1475, 2183, 1964, 1975, 1158, 1718, 1546, 1413, 1080, 1221, 1293, 1270, 7962, 1361, 654, 658, 443, 409, 287, 204, 219, 221, 336, 282, 434, 690, 840, 957, 511, 775, 46, 85, 705, 786, 524, 817, 811, 670, 3310, 2254, 995, 609, 329, 261, 343, 667, 975, 739, 838, 928, 870, 858, 844, 843, 842, 767, 783, 1087, 1101, 1263, 931, 966, 814, 793, 416, 409, 212, 138, 205, 180, 322, 297, 951, 934, 1476, 1390, 862, 577, 548, 131, 108, 91, 680, 1585, 1544, 1044, 987, 749, 590, 377, 310, 223, 225, 320, 422, 562, 939, 1469, 1497, 954, 1333, 1496, 1777, 1230, 1152, 691, 1147, 978, 962, 728, 606, 504, 384, 342, 239, 186, 225, 234, 161, 396, 972, 630, 749, 679, 958, 1449, 5358, 1470, 1153, 825, 811, 717, 792, 717, 688, 579, 437, 369, 222, 181, 163, 201, 226, 292, 508, 665, 1274, 1225, 1579, 1432, 1196, 1173, 1166, 1014, 923, 1204, 1122, 907, 931, 651, 537, 405, 296, 234, 328, 343, 380, 530, 784, 1013, 1500, 1163, 1158, 1356, 804, 1173, 1723, 1187, 1113, 4268, 1784, 1442, 1420, 952, 693, 536, 288, 302, 315, 419, 560, 704, 909, 1246, 1412, 2328, 2168, 2896, 2197, 1689, 1707, 1584, 1216, 1242, 1460, 1127, 1244, 931, 668, 513, 351, 256, 265, 389, 542, 422, 582, 1216, 1610, 1878, 1831, 1716, 1600, 1528, 1700, 1784, 1566, 1464, 1207, 1112, 297, 48, 29, 37, 722, 684, 744, 839, 940, 1347, 1883, 2610, 3033, 3382, 3377, 2423, 2054, 2281, 2340, 2240, 2978, 2536, 1632, 2496, 1032, 536, 1411, 1025, 982, 789, 793, 1345, 1047, 386, 1032, 3902, 4719, 3268, 4883, 6689, 6044, 4686, 4600, 2654, 1399, 400, 911, 506, 554, 531, 394, 293, 239, 293, 249, 282, 376, 525, 708, 916, 1111, 1262, 1328, 1185, 1620, 1432, 1573, 1470, 3976, 4932, 4864, 2368, 3730, 3318, 3031, 2143, 2012, 2173, 2267, 2505, 3267, 5793, 9022, 12048]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.410\n",
      "Model:                            OLS   Adj. R-squared:                  0.404\n",
      "Method:                 Least Squares   F-statistic:                     75.50\n",
      "Date:                Thu, 14 Mar 2019   Prob (F-statistic):           1.43e-48\n",
      "Time:                        21:13:41   Log-Likelihood:                -3990.6\n",
      "No. Observations:                 440   AIC:                             7991.\n",
      "Df Residuals:                     435   BIC:                             8012.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.6089      0.141      4.309      0.000       0.331       0.887\n",
      "x2            -0.0210      0.073     -0.288      0.774      -0.165       0.123\n",
      "x3          2.103e-05   9.81e-06      2.143      0.033    1.74e-06    4.03e-05\n",
      "x4         -4.239e-05   5.79e-05     -0.732      0.465      -0.000    7.14e-05\n",
      "const         26.9118      8.224      3.273      0.001      10.749      43.075\n",
      "==============================================================================\n",
      "Omnibus:                      791.304   Durbin-Watson:                   2.147\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           555962.893\n",
      "Skew:                          11.023   Prob(JB):                         0.00\n",
      "Kurtosis:                     175.740   Cond. No.                     2.14e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.14e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# print(\"Building feature vectors for time period 1\")\n",
    "\n",
    "#tp1\n",
    "tp1_window_size = 3600 # 1 hour window size\n",
    "tp1_start_ts = tp1_window_size * math.floor(tagsToMinTs[tag]/(tp1_window_size*1.0))\n",
    "tp1_end_ts = 1422806400\n",
    "features,labels = getFeatures(tp1_start_ts,tp1_end_ts,tp1_window_size)\n",
    "print(len(features))\n",
    "print(labels)\n",
    "save_object(features, \"q7_tp1_features\")\n",
    "save_object(labels, \"q7_tp1_labels\")\n",
    "\n",
    "X_orig = features\n",
    "y = labels\n",
    "    \n",
    "    #     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X_orig)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature vectors for time period 2\n",
      "144\n",
      "[1300, 1343, 1226, 1302, 1224, 319, 245, 231, 230, 237, 284, 266, 470, 281, 332, 400, 1401, 1493, 1709, 1494, 1593, 1463, 1107, 1716, 1861, 1611, 1544, 1560, 1770, 1676, 1820, 1569, 1697, 8499, 9648, 9991, 5736, 9791, 14318, 15471, 15151, 15241, 13539, 13771, 13805, 15622, 14181, 14508, 13067, 13880, 12876, 12221, 11966, 12615, 11745, 11469, 11083, 11119, 10466, 11276, 10371, 11089, 10611, 10115, 9768, 9986, 9730, 8193, 7300, 7410, 11060, 9837, 9391, 9201, 9217, 8763, 9215, 8532, 9360, 10176, 10267, 10557, 10779, 12747, 20744, 19360, 27623, 25137, 34867, 32175, 34416, 23369, 22546, 20954, 27243, 25419, 23214, 24047, 36027, 25872, 23175, 26587, 30303, 28063, 22709, 26830, 23483, 27450, 34990, 25681, 35025, 45904, 45773, 37186, 23920, 23983, 19550, 17554, 24798, 22708, 13866, 14376, 12927, 12568, 14721, 19292, 17790, 14340, 12789, 28000, 16210, 21143, 35905, 41702, 24998, 17300, 13897, 12540, 9347, 8027, 6915, 5890, 3177, 610]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.847\n",
      "Model:                            OLS   Adj. R-squared:                  0.843\n",
      "Method:                 Least Squares   F-statistic:                     192.4\n",
      "Date:                Thu, 14 Mar 2019   Prob (F-statistic):           1.29e-55\n",
      "Time:                        21:19:10   Log-Likelihood:                -1405.0\n",
      "No. Observations:                 144   AIC:                             2820.\n",
      "Df Residuals:                     139   BIC:                             2835.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0052      0.077     13.038      0.000       0.853       1.158\n",
      "x2            -0.0531      0.023     -2.314      0.022      -0.098      -0.008\n",
      "x3          4.494e-06   1.07e-05      0.422      0.674   -1.66e-05    2.56e-05\n",
      "x4          5.688e-05   5.68e-05      1.001      0.318   -5.54e-05       0.000\n",
      "const         38.6920     42.615      0.908      0.365     -45.564     122.949\n",
      "==============================================================================\n",
      "Omnibus:                       28.518   Durbin-Watson:                   1.943\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               83.559\n",
      "Skew:                           0.714   Prob(JB):                     7.17e-19\n",
      "Kurtosis:                       6.448   Cond. No.                     1.43e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building feature vectors for time period 2\")\n",
    "\n",
    "#tp2\n",
    "tp2_window_size = 300 # 5 minute window size\n",
    "tp2_start_ts = 1422806400\n",
    "tp2_end_ts = 1422849600\n",
    "features,labels = getFeatures(tp2_start_ts,tp2_end_ts,tp2_window_size)\n",
    "print(len(features))\n",
    "print(labels)\n",
    "save_object(features, \"q7_tp2_features\")\n",
    "save_object(labels, \"q7_tp2_labels\")\n",
    "X_orig = features\n",
    "y = labels\n",
    "    \n",
    "    #     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X_orig)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature vectors for time period 3\n",
      "135\n",
      "[16271, 6497, 9039, 5013, 3293, 2602, 2544, 3310, 4070, 4689, 5023, 5052, 4529, 6075, 5143, 7565, 7467, 6555, 6482, 5822, 5175, 4380, 4126, 3566, 2994, 2276, 1863, 1404, 1347, 1225, 1157, 1310, 1397, 1741, 2162, 2377, 2657, 3563, 2801, 2517, 2663, 2253, 1784, 1926, 1609, 1617, 1116, 526, 1268, 1182, 973, 549, 646, 450, 815, 634, 780, 884, 1137, 1407, 1696, 1884, 1489, 1618, 1075, 1305, 1209, 1299, 1167, 909, 1037, 897, 812, 783, 681, 539, 449, 352, 405, 385, 540, 683, 776, 872, 1045, 992, 1080, 1055, 1120, 1154, 983, 920, 906, 869, 865, 537, 679, 727, 524, 256, 406, 416, 441, 429, 514, 380, 915, 1091, 1213, 1150, 1242, 1421, 1558, 1160, 1253, 942, 936, 1220, 983, 852, 856, 882, 503, 411, 30, 28, 26, 13, 17, 36, 36, 85, 59, 49, 52]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.506\n",
      "Model:                            OLS   Adj. R-squared:                  0.491\n",
      "Method:                 Least Squares   F-statistic:                     33.34\n",
      "Date:                Thu, 14 Mar 2019   Prob (F-statistic):           3.99e-19\n",
      "Time:                        21:22:26   Log-Likelihood:                -1181.6\n",
      "No. Observations:                 135   AIC:                             2373.\n",
      "Df Residuals:                     130   BIC:                             2388.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.5093      0.243      2.098      0.038       0.029       0.990\n",
      "x2            -0.0354      0.024     -1.498      0.137      -0.082       0.011\n",
      "x3          2.885e-05    1.3e-05      2.213      0.029    3.06e-06    5.46e-05\n",
      "x4         -2.799e-05   4.69e-05     -0.597      0.552      -0.000    6.48e-05\n",
      "const         32.9263     15.047      2.188      0.030       3.157      62.696\n",
      "==============================================================================\n",
      "Omnibus:                      246.188   Durbin-Watson:                   1.443\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            38279.457\n",
      "Skew:                           8.324   Prob(JB):                         0.00\n",
      "Kurtosis:                      83.796   Cond. No.                     4.57e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.57e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building feature vectors for time period 3\")\n",
    "\n",
    "#tp3\n",
    "tp3_window_size = 3600 # 1 hour window size\n",
    "tp3_start_ts = 1422849600\n",
    "tp3_end_ts = tp3_window_size * math.ceil(tagsToMaxTs[tag]/(tp3_window_size*1.0))\n",
    "features,labels = getFeatures(tp3_start_ts,tp3_end_ts,tp3_window_size)\n",
    "print(len(features))\n",
    "print(labels)\n",
    "save_object(features, \"q7_tp3_features\")\n",
    "save_object(labels, \"q7_tp3_labels\")\n",
    "\n",
    "X_orig = features\n",
    "y = labels\n",
    "    \n",
    "    #     https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b\n",
    "X = sm.add_constant(X_orig)\n",
    "    \n",
    "model = sm.OLS(y,X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print('---'*20)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
