{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 8: \n",
    "\n",
    "Use grid search to find the best parameter set for RandomForestRegressor and GradientBoostingRegressor respectively. Use the following param_grid\n",
    "\n",
    "```\n",
    "{\n",
    "  'max_depth': [10, 20, 40, 60, 80, 100, 200, None],\n",
    "  'max_features': ['auto', 'sqrt'],\n",
    "  'min_samples_leaf': [1, 2, 4],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tags = ['#gohawks','#gopatriots','#nfl','#patriots','#sb49','#superbowl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(data, fileName):\n",
    "    with open('pynb_data/'+fileName + \".pickle\", 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(fileName):\n",
    "    try:\n",
    "        with open('pynb_data/'+fileName + \".pickle\", 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return data\n",
    "    except IOError:\n",
    "        print(\"Could not read file: \" + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def getMinAndMaxTs(tag):\n",
    "    filename = 'data/tweets_'+tag+'.txt'\n",
    "    max_ts = 0\n",
    "    min_ts = 1552522378\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            timestamp = json_object['citation_date']\n",
    "            if(timestamp < min_ts):                \n",
    "                min_ts = timestamp\n",
    "            \n",
    "            if(timestamp > max_ts):\n",
    "                max_ts = timestamp\n",
    "                \n",
    "    return [min_ts,max_ts]\n",
    "\n",
    "tagsToMinTs = {}\n",
    "tagsToMaxTs = {}\n",
    "for tag in hash_tags:\n",
    "    ts_list = getMinAndMaxTs(tag)\n",
    "    tagsToMinTs[tag] = (ts_list[0])\n",
    "    tagsToMaxTs[tag] = (ts_list[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def getLocalHour(timestamp):\n",
    "    d = datetime.datetime.fromtimestamp(timestamp)\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    d = pst.localize(d)\n",
    "    return d.hour\n",
    "\n",
    "def getWindowNumber(start_ts, curr_ts, window):\n",
    "    elapsed = (curr_ts - start_ts)/(window*1.0)\n",
    "    windowNum = math.ceil(elapsed)\n",
    "    return windowNum    \n",
    "\n",
    "def getFeatures(start_ts,end_ts,window):\n",
    "    windowToTweets = {}\n",
    "    windowToRetweets = {}\n",
    "    windowToFollowerCount = {}\n",
    "    windowToMaxFollowers = {}\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for tag in hash_tags:\n",
    "        filename = 'data/tweets_'+tag+'.txt'\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                json_object = json.loads(line)\n",
    "                timestamp = json_object['citation_date']\n",
    "            \n",
    "                if timestamp < start_ts or timestamp > end_ts:                            \n",
    "                    continue\n",
    "                \n",
    "                key = getWindowNumber(start_ts,timestamp,window)\n",
    "    #             print(key)\n",
    "                if key not in windowToTweets.keys():\n",
    "                    windowToTweets[key]=0\n",
    "                windowToTweets[key]+=1\n",
    "            \n",
    "                retweetCount = json_object['metrics']['citations']['total']        \n",
    "            \n",
    "                if key not in windowToRetweets.keys():\n",
    "                    windowToRetweets[key]=0\n",
    "                windowToRetweets[key]+=retweetCount\n",
    "        \n",
    "                followerCount = json_object['author']['followers']\n",
    "                if key not in windowToFollowerCount.keys():\n",
    "                    windowToFollowerCount[key]=0\n",
    "                windowToFollowerCount[key]+=followerCount\n",
    "        \n",
    "                if key not in windowToMaxFollowers.keys():\n",
    "                    windowToMaxFollowers[key]=0\n",
    "                windowToMaxFollowers[key] = max(windowToMaxFollowers[key],followerCount)            \n",
    "            \n",
    "    for period in range(start_ts,end_ts,window):\n",
    "        key = getWindowNumber(start_ts,period,window)\n",
    "        tweetCount = windowToTweets.get(key, 0)\n",
    "        retweetCount = windowToRetweets.get(key,0)\n",
    "        followerCount = windowToFollowerCount.get(key,0)\n",
    "        maxFollowers = windowToMaxFollowers.get(key,0)\n",
    "\n",
    "        h = getLocalHour(key)\n",
    "            \n",
    "        feature = [tweetCount, retweetCount, followerCount, maxFollowers, h]\n",
    "        features.append(feature)\n",
    "                \n",
    "        nextKey = getWindowNumber(start_ts, period + window, window)\n",
    "        labels.append(windowToTweets.get(nextKey,0))\n",
    "                \n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587\n",
      "[111, 89, 110, 100, 137, 169, 215, 353, 569, 533, 530, 544, 525, 628, 611, 675, 260, 256, 233, 342, 402, 334, 258, 119, 88, 275, 155, 173, 336, 160, 291, 479, 632, 563, 304, 528, 651, 534, 626, 614, 376, 398, 496, 387, 243, 258, 203, 65, 145, 34, 20, 42, 180, 115, 185, 687, 885, 954, 704, 981, 1032, 825, 884, 799, 474, 799, 724, 473, 459, 337, 334, 236, 125, 103, 82, 133, 218, 93, 192, 309, 500, 612, 430, 710, 783, 687, 686, 670, 428, 712, 697, 614, 619, 542, 582, 417, 434, 347, 139, 21, 312, 544, 1141, 1839, 2459, 3087, 2493, 6380, 10260, 6702, 7271, 39421, 14572, 8757, 22584, 18564, 4389, 2640, 1997, 1413, 914, 709, 721, 666, 1510, 1123, 1475, 2183, 1964, 1975, 1158, 1718, 1546, 1413, 1080, 1221, 1293, 1270, 7962, 1361, 654, 658, 443, 409, 287, 204, 219, 221, 336, 282, 434, 690, 840, 957, 511, 775, 46, 85, 705, 786, 524, 817, 811, 670, 3310, 2254, 995, 609, 329, 261, 343, 667, 975, 739, 838, 928, 870, 858, 844, 843, 842, 767, 783, 1087, 1101, 1263, 931, 966, 814, 793, 416, 409, 212, 138, 205, 180, 322, 297, 951, 934, 1476, 1390, 862, 577, 548, 131, 108, 91, 680, 1585, 1544, 1044, 987, 749, 590, 377, 310, 223, 225, 320, 422, 562, 939, 1469, 1497, 954, 1333, 1496, 1777, 1230, 1152, 691, 1147, 978, 962, 728, 606, 504, 384, 342, 239, 186, 225, 234, 161, 396, 972, 630, 749, 679, 958, 1449, 5358, 1470, 1153, 825, 811, 717, 792, 717, 688, 579, 437, 369, 222, 181, 163, 201, 226, 292, 508, 665, 1274, 1225, 1579, 1432, 1196, 1173, 1166, 1014, 923, 1204, 1122, 907, 931, 651, 537, 405, 296, 234, 328, 343, 380, 530, 784, 1013, 1500, 1163, 1158, 1356, 804, 1173, 1723, 1187, 1113, 4268, 1784, 1442, 1420, 952, 693, 536, 288, 302, 315, 419, 560, 704, 909, 1246, 1412, 2328, 2168, 2896, 2197, 1689, 1707, 1584, 1216, 1242, 1460, 1127, 1244, 931, 668, 513, 351, 256, 265, 389, 542, 422, 582, 1216, 1610, 1878, 1831, 1716, 1600, 1528, 1700, 1784, 1566, 1464, 1207, 1112, 297, 48, 29, 37, 722, 684, 744, 839, 940, 1347, 1883, 2610, 3033, 3382, 3377, 2423, 2054, 2281, 2340, 2240, 2978, 2536, 1632, 2496, 1032, 536, 1411, 1025, 982, 789, 793, 1345, 1047, 386, 1032, 3902, 4719, 3268, 4883, 6689, 6044, 4686, 4600, 2654, 1399, 400, 911, 506, 554, 531, 394, 293, 239, 293, 249, 282, 376, 525, 708, 916, 1111, 1262, 1328, 1185, 1620, 1432, 1573, 1470, 3976, 4932, 4864, 2368, 3730, 3318, 3031, 2143, 2012, 2173, 2267, 2505, 3267, 5793, 9022, 12048, 8207, 13459, 43246, 161134, 143783, 115470, 118205, 313853, 317760, 357072, 198022, 180308, 16271, 6497, 9039, 5013, 3293, 2602, 2544, 3310, 4070, 4689, 5023, 5052, 4529, 6075, 5143, 7565, 7467, 6555, 6482, 5822, 5175, 4380, 4126, 3566, 2994, 2276, 1863, 1404, 1347, 1225, 1157, 1310, 1397, 1741, 2162, 2377, 2657, 3563, 2801, 2517, 2663, 2253, 1784, 1926, 1609, 1617, 1116, 526, 1268, 1182, 973, 549, 646, 450, 815, 634, 780, 884, 1137, 1407, 1696, 1884, 1489, 1618, 1075, 1305, 1209, 1299, 1167, 909, 1037, 897, 812, 783, 681, 539, 449, 352, 405, 385, 540, 683, 776, 872, 1045, 992, 1080, 1055, 1120, 1154, 983, 920, 906, 869, 865, 537, 679, 727, 524, 256, 406, 416, 441, 429, 514, 380, 915, 1091, 1213, 1150, 1242, 1421, 1558, 1160, 1253, 942, 936, 1220, 983, 852, 856, 882, 503, 411, 30, 28, 26, 13, 17, 36, 36, 85, 59, 49, 52]\n"
     ]
    }
   ],
   "source": [
    "min_ts = min(list(tagsToMinTs.values()))\n",
    "max_ts = max(list(tagsToMaxTs.values()))\n",
    "tp1_window_size = 3600 \n",
    "tp1_start_ts = tp1_window_size * math.floor(min_ts/(tp1_window_size*1.0))\n",
    "tp1_end_ts = tp1_window_size * math.ceil(max_ts/(tp1_window_size*1.0))\n",
    "features,labels = getFeatures(tp1_start_ts,tp1_end_ts,tp1_window_size)\n",
    "print(len(features))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-308543320.26949155\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabketandoshi/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# http://aplunket.com/random-forest-regressor/\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = {\n",
    "  'max_depth': [10, 20, 40, 60, 80, 100, 200, None],\n",
    "  'max_features': ['auto', 'sqrt'],\n",
    "  'min_samples_leaf': [1, 2, 4],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv = KFold(5, shuffle=True), scoring='neg_mean_squared_error')\n",
    "grid.fit(features, labels)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-311303371.9344112\n",
      "{'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabketandoshi/anaconda2/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# http://aplunket.com/random-forest-regressor/\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "param_grid = {\n",
    "  'max_depth': [10, 20, 40, 60, 80, 100, 200, None],\n",
    "  'max_features': ['auto', 'sqrt'],\n",
    "  'min_samples_leaf': [1, 2, 4],\n",
    "  'min_samples_split': [2, 5, 10],\n",
    "  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "newgrid = GridSearchCV(estimator=model, param_grid=param_grid, cv = KFold(5, shuffle=True), scoring='neg_mean_squared_error')\n",
    "newgrid.fit(features, labels)\n",
    "\n",
    "print(newgrid.best_score_)\n",
    "print(newgrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
